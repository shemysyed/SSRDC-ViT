{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML1P7EohTNYxUTJrXRQHaH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shemysyed/SSRDC-ViT/blob/main/pretrainViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HILsBTKqnjl0"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class PreTrain(nn.Module):\n",
        "    def __init__(self, vit):\n",
        "        super().__init__()\n",
        "\n",
        "        decoder_dim = vit.hidden_dim\n",
        "        self.mask_ratio = 0.75\n",
        "        self.patch_size = 16\n",
        "        self.sequence_length = vit.seq_length\n",
        "\n",
        "        self.backbone = MaskedVisionTransformerTorchvision(vit=vit)\n",
        "\n",
        "        # the decoder is a simple linear layer\n",
        "        self.decoder = nn.Linear(decoder_dim, vit.patch_size ** 2 * 3)\n",
        "\n",
        "    def forward_encoder(self, images, batch_size, idx_mask):\n",
        "        # pass all the tokens to the encoder, both masked and non masked ones\n",
        "        return self.backbone.encode(images=images, idx_mask=idx_mask)\n",
        "\n",
        "    def forward_decoder(self, x_encoded):\n",
        "        return self.decoder(x_encoded)\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        idx_keep, idx_mask = utils.random_token_mask(\n",
        "            size=(batch_size, self.sequence_length),\n",
        "            mask_ratio=self.mask_ratio,\n",
        "            device=images.device,\n",
        "        )\n",
        "\n",
        "        # Encoding...\n",
        "        x_encoded = self.forward_encoder(images, batch_size, idx_mask)\n",
        "        x_encoded_masked = utils.get_at_index(x_encoded, idx_mask)\n",
        "\n",
        "        # Decoding...\n",
        "        x_out = self.forward_decoder(x_encoded_masked)\n",
        "\n",
        "        # get image patches for masked tokens\n",
        "        patches = utils.patchify(images, self.patch_size)\n",
        "\n",
        "        # must adjust idx_mask for missing class token\n",
        "        target = utils.get_at_index(patches, idx_mask - 1)\n",
        "\n",
        "        return x_out, target\n",
        "\n",
        "\n",
        "class XrayDataset(Dataset):\n",
        "    def __init__(self, paths, transform=None):\n",
        "        self.paths = paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    _, predicted_classes = predictions.max(1)\n",
        "    correct = (predicted_classes == targets).sum().item()\n",
        "    accuracy = correct / targets.size(0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    vit = torchvision.models.vit_b_32(weights=None)\n",
        "    model = PreTrain(vit)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model_save_path = r\"/content/drive/MyDrive/models/500_model_NIHPADCHESTCOVIDx_pretrainedL2loss_model.pth\"\n",
        "    loss_value_save_path = r\"/content/drive/MyDrive/modelforreconstruction/500_model_NIHPADCHESTCOVIDx_pretrainedL2loss_loss_values.pth\"\n",
        "    accuracy_value_save_path = r\"/content/drive/MyDrive/modelforreconstruction/500_model_NIHPADCHESTCOVIDx_pretrainedL2loss_accuracy_values.pth\"\n",
        "    optimizer_save_path = r\"/content/drive/MyDrive/modelforreconstruction/500_model_NIHPADCHESTCOVIDx_pretrainedL2loss_optimizer.pth\"\n",
        "    scheduler_save_path = r\"/content/drive/MyDrive/modelforreconstruction/500_model_NIHPADCHESTCOVIDx_pretrainedL2loss_scheduler.pth\"\n",
        "    model.to(device)\n",
        "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.5, 1.0), ratio=(3 / 4, 4 / 3)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    #train_data = r\"/content/drive/MyDrive/NIH/Train_filtered\"\n",
        "    train_data = glob.glob(r'/content/drive/MyDrive/NIH/Train_filtered\\*')\n",
        "    train_path = train_data\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = XrayDataset(paths=train_path, transform=transform)\n",
        "    dataset = train_dataset\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=512,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=8,\n",
        "    )\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1.5e-4, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
        "    optimizer.load_state_dict(torch.load(optimizer_save_path))  # Resume optimizer state\n",
        "    scheduler.load_state_dict(torch.load(scheduler_save_path))  # Resume scheduler state\n",
        "    print(\"Starting Training\")\n",
        "    loss_value: List[float] = []  # Initialize loss_value as an empty list of floats\n",
        "    accuracy_value: List[float] = []\n",
        "    num_epochs = 100  # Total epochs after fine-tuning\n",
        "\n",
        "    total_start_time = time.time()  # Record the start time of the training loop\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()  # Record the start time of the epoch\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        model.train()\n",
        "        for batch in dataloader:\n",
        "            images = batch.to(device)\n",
        "\n",
        "\n",
        "            predictions, targets = model(images)\n",
        "            # Flatten the predictions and targets to calculate the accuracy\n",
        "            predictions = predictions.view(-1, 3, model.patch_size, model.patch_size)\n",
        "            targets = targets.view(-1, 3, model.patch_size, model.patch_size)\n",
        "            loss = criterion(predictions, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate element-wise accuracy for the batch\n",
        "            accuracy = ((predictions - targets).abs() < 0.1).float().mean().item()\n",
        "            total_accuracy += accuracy\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        avg_accuracy = total_accuracy / len(dataloader)\n",
        "        loss_value.append(avg_loss)  # Append the average loss for the current epoch\n",
        "        accuracy_value.append(avg_accuracy)\n",
        "        scheduler.step()\n",
        "        epoch_end_time = time.time()  # Record the end time of the epoch\n",
        "        epoch_time = epoch_end_time - epoch_start_time  # Calculate the epoch duration\n",
        "        print(f\"epoch: {epoch + 1:>02}, loss: {avg_loss:.5f}, accuracy: {avg_accuracy:.5f}, time: {epoch_time:.2f}s\")\n",
        "\n",
        "    total_end_time = time.time()  # Record the end time of the training loop\n",
        "    total_training_time = total_end_time - total_start_time  # Calculate the total training time\n",
        "    print(f\"Total training time for {num_epochs} epochs: {total_training_time:.2f}s\")\n",
        "\n",
        "    print(\"Training completed. Loss values and accuracy for each epoch:\")\n",
        "    print(loss_value)\n",
        "    print(accuracy_value)\n",
        "    # Plotting loss after the training loop\n",
        "    plt.plot(loss_value, label='Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model state dictionary and loss/accuracy values after all epochs\n",
        "    save_path = r\"C:\\PROJECT FILES\\Models_saved\\fine tune models\\finetune_reconstruction\\nih_reconstruction_finetunedfrom pretrained\" # Directory to save models\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    unique_identifier = \"finetunalltrain_forreconstruction_frombasemodel_.weightdecay01\"  # Change this for each model\n",
        "    model_save_path = os.path.join(save_path, f\"{unique_identifier}_model.pth\")\n",
        "    loss_value_save_path = os.path.join(save_path, f\"{unique_identifier}_loss_values.pth\")\n",
        "    accuracy_value_save_path = os.path.join(save_path, f\"{unique_identifier}_accuracy_values.pth\")\n",
        "    optimizer_save_path = os.path.join(save_path, f\"{unique_identifier}_optimizer.pth\")\n",
        "    scheduler_save_path = os.path.join(save_path, f\"{unique_identifier}_scheduler.pth\")\n",
        "    config_save_path = os.path.join(save_path, f\"{unique_identifier}_config.pth\")\n",
        "\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    torch.save(loss_value, loss_value_save_path)  # Save loss values\n",
        "    torch.save(accuracy_value, accuracy_value_save_path)  # Save accuracy values\n",
        "    torch.save(optimizer.state_dict(), optimizer_save_path)  # Save optimizer state\n",
        "    torch.save(scheduler.state_dict(), scheduler_save_path)  # Save scheduler state\n",
        "\n",
        "    # Save training configuration\n",
        "    config = {\n",
        "        'learning_rate': 1.5e-4,\n",
        "        'weight_decay': 0.01,\n",
        "        'batch_size': 512,  # Updated batch size\n",
        "        'num_epochs': num_epochs,\n",
        "        'mask_ratio': model.mask_ratio,\n",
        "        'patch_size': model.patch_size,\n",
        "        'sequence_length': model.sequence_length,\n",
        "    }\n",
        "    torch.save(config, config_save_path)\n",
        "\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "    print(f\"Loss values saved to {loss_value_save_path}\")\n",
        "    print(f\"Accuracy values saved to {accuracy_value_save_path}\")\n",
        "    print(f\"Optimizer state saved to {optimizer_save_path}\")\n",
        "    print(f\"Scheduler state saved to {scheduler_save_path}\")\n",
        "    print(f\"Training configuration saved to {config_save_path}\")\n"
      ]
    }
  ]
}